{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe5bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bca89a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import MarkdownConverter\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e753397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "years = range(1980, 2023)\n",
    "months = ['04', '10']\n",
    "host = 'https://www.churchofjesuschrist.org'\n",
    "base_dir = '../data'\n",
    "bs_parser = 'html.parser'\n",
    "encoding = 'utf-8'\n",
    "seconds_delay = 30\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\", \n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\", \n",
    "    \"Sec-Ch-Ua\": \"\\\"Google Chrome\\\";v=\\\"105\\\", \\\"Not)A;Brand\\\";v=\\\"8\\\", \\\"Chromium\\\";v=\\\"105\\\"\", \n",
    "    \"Sec-Ch-Ua-Mobile\": \"?0\", \n",
    "    \"Sec-Ch-Ua-Platform\": \"\\\"Linux\\\"\", \n",
    "    \"Sec-Fetch-Dest\": \"document\", \n",
    "    \"Sec-Fetch-Mode\": \"navigate\", \n",
    "    \"Sec-Fetch-Site\": \"cross-site\", \n",
    "    \"Sec-Fetch-User\": \"?1\", \n",
    "    \"Upgrade-Insecure-Requests\": \"1\",     \n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2c51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HrefConverter(MarkdownConverter):\n",
    "    \"\"\"\n",
    "    Create a custom MarkdownConverter that joins hrefs with a base url\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(HrefConverter, self).__init__(*args, **kwargs)\n",
    "        self.base_url = kwargs.get('base_url','')\n",
    "        \n",
    "    def convert_a(self, el, text, convert_as_inline):\n",
    "        if 'href' in el.attrs:\n",
    "            el['href'] = urljoin(self.base_url, el['href'])\n",
    "        return super().convert_a(el, text, convert_as_inline)\n",
    "\n",
    "\n",
    "# Create shorthand method for custom conversion\n",
    "def md(html, **options):\n",
    "    return HrefConverter(**options).convert(html)\n",
    "\n",
    "\n",
    "def get_page(url, headers, encoding):\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if encoding:\n",
    "        response.encoding = encoding\n",
    "    return response.status_code, response.text\n",
    "\n",
    "\n",
    "def _is_talk_url(url):\n",
    "    path_components = urlparse(url).path.split('/')\n",
    "    # must be 5 components and last component must not end in -session\n",
    "    return len(path_components) == 6 and not path_components[-1].endswith('-session')\n",
    "\n",
    "\n",
    "def get_talk_urls(base_url, html):\n",
    "    soup = BeautifulSoup(html, bs_parser)\n",
    "    return [urljoin(base_url, a['href']) for a in soup.find_all('a', href=True) \\\n",
    "            if _is_talk_url(urljoin(base_url, a['href']))]\n",
    "\n",
    "\n",
    "def _clean(text):\n",
    "    return text.replace('Â ', ' ')\n",
    "\n",
    "\n",
    "def get_talk_info(url, html):\n",
    "    path_components = urlparse(url).path.split('/')\n",
    "    year, month = path_components[3:5]\n",
    "    soup = BeautifulSoup(html, bs_parser)\n",
    "    title = soup.select_one('article header h1')\n",
    "    author = soup.select_one('article p.author-name')\n",
    "    author_role = soup.select_one('article p.author-role')\n",
    "    body = soup.select_one('article div.body-block')\n",
    "    content = _clean(md(str(body), base_url=url)) if body else ''\n",
    "\n",
    "    return {\n",
    "        'year': year,\n",
    "        'month': month,\n",
    "        'url': url,\n",
    "        'title': _clean(title.text) if title else '',\n",
    "        'author': _clean(author.text) if author else '',\n",
    "        'author_role': _clean(author_role.text) if author_role else '',\n",
    "        'content': content,\n",
    "        'html': html,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_talk_path(url):\n",
    "    path_components = urlparse(url).path.split('/')\n",
    "    year, month, title = path_components[3:6]\n",
    "    return os.path.join(base_dir, f\"{year}-{month}-{title}.json\")\n",
    "\n",
    "\n",
    "def write_talk_info(path, talk_info):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(talk_info, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ebfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    for month in months:\n",
    "        dir_url = f\"{host}/study/general-conference/{year}/{month}?lang=eng\"\n",
    "        status_code, dir_html = get_page(dir_url, headers, encoding)\n",
    "        if status_code != 200:\n",
    "            print(f\"Status code={status_code} url={dir_url}\")\n",
    "            continue\n",
    "        talk_urls = get_talk_urls(dir_url, dir_html)\n",
    "        print(dir_url, len(talk_urls))\n",
    "        time.sleep(seconds_delay)\n",
    "        for talk_url in talk_urls:\n",
    "            path = get_talk_path(talk_url)\n",
    "            if os.path.exists(path):\n",
    "                continue\n",
    "            print(\"    \", path)\n",
    "            status_code, talk_html = get_page(talk_url, headers, encoding)\n",
    "            if status_code != 200:\n",
    "                print(f\"Status code={status_code} url={talk_url}\")\n",
    "                continue\n",
    "            talk_info = get_talk_info(talk_url, talk_html)\n",
    "            if not talk_info['title'] or not talk_info['author'] or not talk_info['content']:\n",
    "                print(\"Missing data\", talk_url)\n",
    "            write_talk_info(path, talk_info)\n",
    "            time.sleep(seconds_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac949b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enrichify",
   "language": "python",
   "name": "enrichify"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
